#!/usr/bin/env python3
"""
Minimal speed test for existing CSP network.
Tests current performance before applying optimizations.
"""

import asyncio
import sys
import time
import json
from pathlib import Path

# Add current directory to path
sys.path.insert(0, str(Path(__file__).parent))

async def test_existing_transport():
    """Test the existing transport performance."""
    print("ğŸ” Testing existing CSP network transport...")
    
    try:
        # Try to import existing transport
        from p2p.transport import MultiProtocolTransport
        from core.config import P2PConfig
        
        # Create basic config
        config = P2PConfig(
            listen_port=30301,  # Use different port for test
            enable_quic=False,
            connection_timeout=5,
        )
        
        print(f"âœ… Successfully imported existing transport")
        print(f"   Transport: MultiProtocolTransport")
        print(f"   Config: {config.listen_port}")
        
        # Create transport instance
        transport = MultiProtocolTransport(config)
        
        # Start transport
        print("ğŸš€ Starting transport...")
        success = await transport.start()
        
        if success:
            print("âœ… Transport started successfully")
            
            # Test basic message creation
            test_messages = []
            for i in range(100):
                message = {
                    "type": "test",
                    "id": i,
                    "data": f"Test message {i}" * 10,  # ~150 bytes
                    "timestamp": time.time()
                }
                test_messages.append(message)
            
            print(f"ğŸ“Š Created {len(test_messages)} test messages")
            
            # Simulate message processing time
            start_time = time.perf_counter()
            processed = 0
            
            for msg in test_messages:
                # Simulate message handling (serialization, etc.)
                json_data = json.dumps(msg)
                parsed_data = json.loads(json_data)
                processed += 1
            
            end_time = time.perf_counter()
            duration = end_time - start_time
            msg_per_sec = processed / duration
            
            print(f"ğŸ“ˆ Current Performance (baseline):")
            print(f"   Messages processed: {processed}")
            print(f"   Time taken: {duration*1000:.1f}ms")
            print(f"   Rate: {msg_per_sec:.0f} messages/second")
            print(f"   Avg per message: {(duration/processed)*1000:.2f}ms")
            
            # Stop transport
            await transport.stop()
            print("âœ… Transport stopped")
            
            return msg_per_sec
            
        else:
            print("âŒ Failed to start transport")
            return 0
            
    except ImportError as e:
        print(f"âŒ Cannot import existing transport: {e}")
        print("   Make sure you're in the right directory with the network files")
        return 0
    except Exception as e:
        print(f"âŒ Transport test failed: {e}")
        return 0


def estimate_optimization_gains(baseline_rate):
    """Estimate performance gains from optimizations."""
    if baseline_rate <= 0:
        print("âš ï¸  Cannot estimate gains without baseline measurement")
        return
    
    print(f"\nğŸ¯ Estimated Performance Gains with Optimizations:")
    print("=" * 55)
    
    optimizations = [
        ("Current (baseline)", 1.0, baseline_rate),
        ("+ Fast Serialization", 1.4, baseline_rate * 1.4),
        ("+ Intelligent Batching", 3.5, baseline_rate * 1.4 * 2.5),
        ("+ Compression", 3.5, baseline_rate * 1.4 * 2.5 * 1.0),  # Same CPU, saves bandwidth
        ("+ Connection Pooling", 7.0, baseline_rate * 1.4 * 2.5 * 2.0),
        ("+ Zero-Copy I/O", 10.5, baseline_rate * 1.4 * 2.5 * 2.0 * 1.5),
        ("+ QUIC Protocol", 14.0, baseline_rate * 1.4 * 2.5 * 2.0 * 1.5 * 1.33),
        ("+ Topology Optimization", 17.5, baseline_rate * 1.4 * 2.5 * 2.0 * 1.5 * 1.33 * 1.25),
    ]
    
    print(f"{'Configuration':<25} {'Multiplier':<12} {'Est. Rate (msg/s)'}")
    print("-" * 55)
    
    for config, multiplier, estimated_rate in optimizations:
        print(f"{config:<25} {multiplier:<12.1f}x {estimated_rate:<12.0f}")
    
    final_improvement = optimizations[-1][1]
    print(f"\nğŸš€ Expected Overall Improvement: {final_improvement:.1f}x faster")
    print(f"ğŸ’¡ From {baseline_rate:.0f} to {baseline_rate * final_improvement:.0f} messages/second")


def show_optimization_roadmap():
    """Show the optimization implementation roadmap."""
    print(f"\nğŸ—ºï¸  Optimization Implementation Roadmap:")
    print("=" * 50)
    
    phases = [
        ("Phase 1 - Quick Wins", [
            "âœ… Fast Serialization (protocol_optimizer.py)",
            "âœ… Intelligent Batching (batching.py)",
            "Expected gain: ~3.5x performance"
        ]),
        ("Phase 2 - Network Optimization", [
            "âœ… Connection Pooling (connection_pool.py)",
            "âœ… Adaptive Compression (compression.py)",
            "Expected gain: ~7x performance"
        ]),
        ("Phase 3 - Advanced Features", [
            "âœ… Zero-Copy I/O (zero_copy.py)",
            "âœ… QUIC Protocol (p2p/quic_transport.py)",
            "Expected gain: ~14x performance"
        ]),
        ("Phase 4 - Intelligence", [
            "âœ… Topology Optimization (adaptive_optimizer.py)",
            "âœ… Full Integration (optimized_channel.py)",
            "Expected gain: ~17x performance"
        ])
    ]
    
    for phase_name, items in phases:
        print(f"\n{phase_name}:")
        for item in items:
            print(f"  {item}")


async def main():
    """Main test function."""
    print("âš¡ CSP Network Speed Test")
    print("=" * 30)
    print("Testing current performance and optimization potential...\n")
    
    try:
        # Test existing transport
        baseline_rate = await test_existing_transport()
        
        # Show optimization estimates
        estimate_optimization_gains(baseline_rate)
        
        # Show roadmap
        show_optimization_roadmap()
        
        print(f"\nğŸ‰ Speed test completed!")
        print(f"ğŸ’¡ Ready to implement optimizations for massive performance gains!")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸  Test interrupted by user")
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
